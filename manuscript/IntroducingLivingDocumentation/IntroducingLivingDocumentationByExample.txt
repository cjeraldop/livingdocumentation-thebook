# Introducing Living Documentation by example, on batches to export credit authorizations to external systems

The first question is: what do we need to document to improve the life of the development team? Based on the answers, and looking at the current state of the available documentation, we can then propose actions to better manage the knowledge.

Currently, there are some documents but they are out of date and not reliable. We usually have to ask the most knowledgeable team member all the time to get the knowledge needed to perform any task.

There's a lot of potential for improvement, including some quick wins. We could introduce all the items below to start a Living Documentation journey.

## README, READY-MADE documentation, AUGMENTED CODE

Add a README file at the root of the module mentioning clearly that this module follows the **Data Pump pattern** with a brief explanation and a link to a reference on the web. From a Living Documentation perspective, we are referencing a READY-MADE documentation.

To be more useful, we can elaborate on the data pump with a description of its main parameters in the README file:

- **Target system & format**: Company standard XML dialect
- **Governance**: this data pump belongs to the Credit Approval component and is managed as part of it

Include links to a folder with some sample files as describing the input and outputs of the component:

     Sample input and output files can be found in '/samples/' (with a link to 'target/doc/samples')

## Business Behavior

The eligibility determination which is the core complexity of the module is best described by business scenarios. Note that some of these same scenarios also generate the sample files seen before.

Then we need to make these scenarios accessible to non-developers. The basic Cucumber Report can show the scenarios as a web page online. You may consider the alternative Pickles for the living documentation to be available online to anyone in a better form and with a search engine.

## Visible Workings and Single Source of Truth

The transcoding used to generate the XML report is defined in code, and in an Excel file as well:

     <input field name, output field name, formatter>.

We realize this is duplication for no value. We could improve that by considering the spreadsheet as the single source of truth (aka golden source). The code then parses the file and interprets it to drive its behavior. In this approach, the file is directly its own documentation. You may go the other way round, by deciding that the code is the single source of truth and you generate a file directly out of the code.

Both ways won't work if your code is mostly made of a lot of IF statements. They both impose some generic structure to the design of the code. For example:

for each input field, lookup the corresponding output field, and apply the formatted to obtain the value to assign.

## Integrated Documentation for developers, Living Glossary for other stakeholders

Do you really need to produce Javadoc reports? It's so easy to browse the code in your IDE that you probably won't use the Javadoc reports much. The Javadoc reports are now available directly at your fingertips in your IDE. The same is true for UML class diagrams of classes and their type hierarchies. All this is already Integrated Documentation built-in your editors.

If you really need a reference to give access to the concepts to non-developers, you may introduce a little Living Glossary. It scans the code in the /domain package to generate a markdown and HTML glossary of all the business domain concepts in the code, extracted from classes, interfaces, enum constants and perhaps some methods names and Javadoc comments. Of course, for the glossary to be good you'll probably have to review and fix many of these Javadoc comments.

## Living Diagram to show the design intent

If the internal design follows a known structure like the Hexagonal architecture, we can make it visible thanks to naming conventions. The naming convention and the name of the structure are documented in the README file.

The design of this module follow the Hexagonal architecture pattern (link to a reference on the web).

By convention, the domain model code is in the 'src/*/domain*/' package, and the rest is all infrastructure code

You may include a link to the domain model package, but it has to survive refactoring changes like nesting the domain into another package; to make the link more stable we can make it a bookmarked search direclty based on the naming convention as a regex: src/*/domain*/

## Contact information, and Guided Tour

Who should I contact for questions? Just check the service registry, Consul in our case.

How does our module fit within the bigger system? Answering this question takes more effort. One approach would be to regularly run a journey test on some environment with distributed tracing in place. You may use Selenium and Zipkin for that. You could then visualize the distributed traces to produce another kind of Guided Tour to reveal the big picture along one typical end-to-end scenario.
