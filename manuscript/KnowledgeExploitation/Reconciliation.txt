# Reconciliation Mechanism (aka Verification Mechanism)

Duplication of knowledge about a software is a bad thing because it implies recurring work to update all the places that are redundant to each other, and it also implies a risk of getting into an inconsistent state when an update is forgotten.

However if you have to accept redundancy you can relieve the pain thanks to a Verification Mechanism, for example an automated test that checks that both copies are always in sync. This does not remove the cost of making changes more than one place, but at leasts it ensures you won't forget one change somewhere.

One reconciliation mechanism everybody's familiar with is checking the bill in the restaurant. You know what you ate, which may be still visible by looking at the number of dishes, and you check each line on the bill to check there's no discrepancy.

![Checking the restaurant bill is a reconciliation mechanism](images/Reconciliation.png)

**Therefore: When you want or have to accommodate a redundancy in the knowledge stored at various places, make sure all the redundant knowledge is kept consistent thanks to a Reconciliation Mechanism. Use automation to make sure everything remains in sync, and that any discrepancy is detected immediately with an alert prompting to fix it.**

![Automated mechanism to verify the redundant knowledge is in sync](images/reconciliation_mechanism.jpg)

## Consistency Tests

A well-known example is BDD, where the scenarios are the documentation of the behavior. Whenever scenario and code disagree, it shows immediately because the test automation fails.

This mechanism is made possible thanks to tools that parse the scenario in natural domain language to drive their implementation code. The code is driven through a little layer of glue code that you write specifically for that purpose, usually called "Steps Definitions". These are adapters between the parsed scenario and the actual code being driven.

Imagine testing the following scenario:

- Given party BARNABA is marked as bankrupt
- And the trade 42 is against BARNABA
- When the risk alerting calculation is ran
- Then an alert: Trade against the bankrupt party BARNABA is triggered

The tool parses these lines of text, and recognizes the sentence "Given party BARNABA is marked as bankrupt" as one it has a step definition for:

~~~~~~~~
Given("^party (.*) is marked as bankrupt$")
public void partyMarkedAsBankrupt(string party){
  bankruptParties.put(party);
}
~~~~~~~~

The tools does the same for each line. Typically sentences starting with *When* trigger actual computation, and sentences starting with *Then* check assertions:

~~~~~~~~
Given("^Then an alert: (/*) is triggered$")
public void anAlertIsTriggered(string expectedMessage){
  assertEquals(expectedMessage, actualMessage);
}
~~~~~~~~

You realize, of course, that for this all this mechanism to work, the sentences need to actually drive the code with parameters, and the assertions must check against the expectations from the sentences as precisely as possible.

As a counter example, it would not make less sense to code the step without extracting parameter from the sentence, or we would run again a risk of being inconsistent after a few changes:

~~~~~~~~
Given("^Then an alert: Trade against the bankrupt party BARNABA is triggered$")
public void anAlertIsTriggered(){
  assertEquals("Trade against the bankrupt party ENRON", actualMessage);
}
~~~~~~~~

The scenario would pass even if the code had changed its behavior.

## Reconciliation on the test assumptions

Usually we use the given (or their equivalent "Arrange" phase in plain xUnit code) to create mocks or to inject data into the test database.

When testing legacy systems, it happens that you have to deal with a number of bad news:

- it's too hard to mock the database so you have to test in an end-to-end fashion
- you can't re-create or populate a database just for you tests so you have to work on a real shared database that can change anytime if someone else decides to.

In this case it's still possible to use the exact same declaration of an assumption as a *When* sentence or an Arrange phase in xUnit, but with an implementation that checks that the assumption still holds true instead of injecting the value into a mock:

~~~~~~~~
Given("^party (.*) is marked as bankrupt$")
public void partyMarkedAsBankrupt(string party){
  assertTrue(bankruptParties.isBankruptParty(party)); // calls the DB
}
~~~~~~~~

This not an assertion of the test, it's just a pre-requisite for the scenario (or test) to even have a chance to pass. If this assumption already fails, then the scenario "does not even fail".

I often call this kind of "tests before the tests" *Canary Tests*. They tell something's wrong even outside of the test focus, so that we know we don't have to waste time investigating in the wrong place.

## Published Contracts

Another flavor of Reconciliation Mechanism that I have first seen used by my Arolla colleague Arnauld Loyer can be used on purpose to respect contracts against third parties like external services that call your services. If your services exposes a resource with a parameter *CreditDefaultType*, with two possible values *FAILURE_TO_PAY* and *RESTRUCTURING*, you can't rename them as you wish once published.

So you may use tests, with a deliberate redundancy with respect to these elements of the contract, to enforce that they don't change. You can refactor and rename as you wish, but whenever you break the contract, the reconciliation tests will alert you with a test failure.

This is an example of an enforced documentation: ideally you would make the test the reference documentation of the contract (some tools in the API sphere enable to do that) in a readable form. Here you definitely don't want to update the test through automated refactoring, you want it out of reach of the refactoring so that it stays unchanged to represent the external consumer services.

The most naive implementation for this approach would be something like that, assuming that the internal representation of the CreditDefaultType is a Java enum named *CREDIT_DEFAULT_TYPE*:

~~~~~~~~
@Test
public void enforceContract_CreditDefaultType
  final String[] contract = {"FAILURE_TO_PAY", "RESTRUCTURING"};

  for(String type : contract){
    assertEquals(type, CREDIT_DEFAULT_TYPE.valueOf(type).toString());
  }
}
~~~~~~~~

Since we want to make sure that the contract for the external calling code is respected, we define this contract *again* as an array of strings, like it's being used from the outside. And since we want to check the contract is being honed with incoming and outcoming values, we make sure the contractual string is recognized as an input with the *valueOf()*, and that it's the one being sent as an output with the *toString()*.

This example is only to explain the idea, in practice it's bad practice to use a loop inside a test as the test reporting will not tell precisely at which loop the problem was in case there's an exception. We would use a Parameterized test instead, putting the collection of values that are part of the contract as the source of parameters, but this is not the focus of the discussion.

With this approach, when a new joiner to the team decides to rename a constant of the enum, the test immediately fails to signal that it's not possible to do that, in effect acting like a defensive documentation. It's a defense against misconduct, and at the same time when there's misconduct by ignorance, it's the opportunity for the violator to learn on the spot. It's another flavor of embedded learning.
