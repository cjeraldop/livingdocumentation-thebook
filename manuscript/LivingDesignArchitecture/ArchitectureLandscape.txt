# Architecture Landscape

## Architecture and documentation

There is a close relationship between architecture and documentation.

How do you document the architecture of your system? The short answer is that whatever what you call architecture, doing architecture is in itself an act of documentation between every people involved in the project.

Many definitions of architecture have been proposed over the past decades, but the following two are my favorite:

1. Things that everybody should know
1. Things that are hard to change

The first definition in itself admits that architecture is totally a matter of shared knowledge, hence a matter of documentation. The second definition is more precise, but it seems likely that the things that are hard to change should also be known by everyone.


## Everybody should know about the problem

Architecture always starts with really understanding all the objectives and constraints of the problem to solve. You won't build the same point-of-sale system for a brand with 50 hot dog stands in the street as you would for a 1500 high-end pret-Ã -porter shops around the world, even if they have the same high-level basic features.

The high-level goals, and the main constraints are "things that everybody should know", and as such they are always part of the architecture.

Therefore: **Whatever your definition of architecture, make sure it is considered as much a documentation challenge as a technical one. Focus the discussions and their written records on the problems to solve, not just on the solutions. Make sure the essential knowledge about the problem is well described in a persistent form, and ensure it is in everybody's mind.**

You may ask random questions from time to time to check everyone involved knows about the essential business knowledge. I regularly like to do that, since it it's not the case we'll probably waste a lot of time during every discussion.

Keep in mind that written form is almost never enough, not everyone will read it. You'd better complement with random discussions and roadshows to present it to every team during official work time.

### An example of a problem brief

Here is an example inspired from a real-world project on a legacy system for one of my customer.

The brief is not in the wiki, but in a single Markdown text file at the root of the source code repository of the new component. It may even be in the README file.

> # Vision Statement
>
>Date: 01/06/2015
>
>*Delight the users with great UI's and new features delivered frequently*
>
>
>## Description
>
>The INSURANCE 2020 program aims at revamping the legacy software supporting the insurance claim management processes, with two main goals in target:
>
>1. User Experience (UX) & user-friendliness UI's
>2. Continuous Delivery: reduced time to market and reduced cost of change
>
>
>## Stakeholders
>
>The primary stakeholders are the Insurance Adjusters.
>
>Other stakeholders are:
>
>- Actuaries
>- Management
>
>IT-related stakeholders are:
>
>- Development team
>- Central Architecture Group
>- Support and Ops teams
>
>## Business Domain
>
>The business domain focuses on the claim management part, and in particular the Claim Adjustment phase. This starts at the early mention of a claim to start every investigation necessary to plan, witness the damages, contact the police officers, lawyer in order to propose a monetary amount to give to the policy holder.
>
>The main business capabilities include for example:
>
>- Take note of a claim without much information about it
>- Enrich the claim whenever more information is available: parties involved, checks, evidences, photographs...
>- Prepare the claim with one or more possible settlement offer(s) (each made of one or more monetary amount(s))
>- Manage the claim team and the related workflows
>- Report the current state of one or all pending claims
>- Help users see their tasks to do at any time
>


## Quality Attributes

In software, quality attributes shape the solution. The technical solution to a given business problem will be radically different for millions of concurrent users as opposed to 100 concurrent users, if it's real-time as opposed to daily, or if each minute of downtime cost $500k to the company.

As a consequence, everybody should be aware of the most challenging quality attributes. They should also understand that other quality attributes are which are not challenging are opportunities to keep the architecture simple. Pretending that your design should support millions of concurrent users when you really have only thousands is a dangerous misuse of the sponsor's money and time.

**Therefore: At the start of a project, clarify the main quality attributes in writing. It can be as simple as a list of bullet points. Make it clear how to interpret the quality attributes, for example using maxims as guidance.**

An example of describing the main quality attributes.

> The system shall respond to user requests with a response time within 1 second for 98% of the transactions. The system shall support 3000 concurrent users.

It should come with some internal guidance on how to interpret the quality attribute, for example:

> Overquality is NOT quality

> Design for ~10X growth, but plan to rewrite before ~100X -- [Jeff Dean (Google)](http://static.googleusercontent.com/media/research.google.com/en//people/jeff/WSDM09-keynote.pdf)

These quality attributes can then be turned into executable scenarios against the system, expressing the quality attributes literally in plain English sentences (see Test-Driven Architecture).

## Stake-Driven Architecture Documentation

We've seen before two definitions of architecture: "Things that everybody should know", and "Things that are hard to change. There are many other perspectives on architecture. Some developers consider architecture as being all about the large-scale system with its infrastructure, expensive middleware, distributed components and databases replication. In fact this is normal for different people working on different systems to focus on different aspects of software and call it "architecture": they call architecture the aspects of the software which are most at stake in their context.

This diversity of perspectives is made obvious when doing an Architectural Kata. During this workshop format proposed by Ted Neward, groups of people are tasked in creating an architecture for a given business problem. Each group has 30mn and a big piece of paper with markers to prepare and present a proposal. The rules clearly emphasizes that the group should be able to justify any decision taken. The workshop ends with each group presenting its architecture to everyone else, as if they were defending the proposal in front of a client. Other attendees are invited to ask questions to challenge the proposal, as a skeptical client would do.

This workshop is very interesting to think about architecture. It is in itself a communication exercise. It is not just about the decisions taken, it is also about expressing them in a convincing way. Almost invariably, this kata reveals how different people think very differently about the same problem.

A> You may be tempted to use this kata on real business cases, as a form of competitive engineering, with different groups proposing different views which are later compared. However the risk is that on a real case would be to have "winners" and "losers" groups at the end. You should practice it several times as a pure kata first, without real stakes. You will get a lot of value and thinking out of it, and you will also learn how to avoid the "winner vs. loser" effect.

What I learnt from this kata is that different business problems call for a focus on different areas. The main aspect of point of sale system in the street is to be lightweight, cheap in case it is stolen, and easy to use while making hog dogs in a hurry in the middle of a little crowd. In contrast, a mobile app meant to sell itself on an app store has to be primarily visually attractive, whereas an enterprise system meant to serve millions of transactions by second should before all focus on performance as its main stake. And there are systems where the main stake is on their deeper understanding of the business domain.

These key stakes of the system are what should be primarily recorded for everyone to know.

Therefore: **Identify early the main stake of the project: business domain challenge, technical concern, quality of the user-experience, integration with other systems... You may ask the question: "What would most easily make the project a failure?". Make sure your documentation efforts primarily cover this main stake.**

To caricature, don't spend too much of your time documenting the server technology stack when the main stake of the whole project is on the UX.


## Explicit Assumptions

When knowledge is incomplete, like it usually is at the beginning of any interesting project, we make assumptions. Assumptions make it possible to move on, but at the expense of potentially being shown wrong later on. It is a matter of documentation to make it cheaper to rewind the tape when you reconsider an assumption. A simple way to do that is to explicitly mark decisions with the assumptions they depend upon. This way, when an assumption is reconsidered, it is possible to find all its consequences, to reconsider them in turn. For this to work efficiently, it should all be done as an Internal Documentation, in place within the decisions, i.e. usually in the source code itself.



### Brief to explain

A good architecture is simple and looks obvious. It is also easy to describe in just a few sentences. A few key decisions, sharp and opinionated, which guide every other decision is a good architecture.

If architecture is "what everyone should know", then this puts an upper bound on its complexity. Anything complex to explain will not be understood by most.

A> I've seen a good example of a good architecture in Fred George's talk at Oredev 2013 on micro-services architecture. Fred Georges manages to explain the key ideas of this architecture in minutes. It sounds as if it was simplified, and it probably is, deliberately. There is a lot of value in a caricatural architecture, which can be quickly understood by everyone. On the other hand, optimizing every detail is harmful if it makes the whole impossible to explain quickly.

**Therefore: Try to express the architecture out loud in less than 2 minutes as a test of its quality. If you succeed, then write it down immediately. If it takes much longer and too many sentences to explain the architecture, then it can probably be improved a lot.**

### Evolving continuously - Change-Friendly Documentation

The best architecture is an evolving creature, since it is hard to get it right at first try, and then it has to adapt to the changing context.

A good architecture is easy to explain succinctly and minimizes the number of decisions that are hard to change. But whatever is left hard to change or that everybody should know has to be documented. It has to be persistent over time and made accessible to everyone, by definition.

This means that whatever makes the architecture or its documentation hard or expensive to change must be avoided. Your team should learn how to make reversible decisions, or to defer irreversible decisions. And if you fear changing the architecture because you have a lot of static documentation about it that would have to be redone, then your documentation is harming you and you should reconsider how you do it.


**Pay attention to how much words and diagrams are needed to explain the architecture, the less being probably the better.**

Keep it all evolving, removing any process or artifact which would impede continuous change.


## Architecture Steering

> Architecture should not be defined but rather discovered, refined, evolved, and explained. #theFirstMisconceptionAboutArchitecture -- @mittie

The old-fashioned idea of architecture as something to perform *before* doing the implementation doesn't fit well with modern projects. Change is expected everywhere and at anytime, in the code and in the architecture, whatever you call architecture.

Software architecture is about making sure that the major quality attributes of the overall system are met (e.g. conceptual integrity, performance, maintainability, security, fault-tolerance...) and communicating the most important decisions to everyone involved.

Documentation in any form is therefore an integral part of what architecture really is. But we don't want old-fashioned architecture practices to slow down our projects. We want fast documentation that can help communicate knowledge to everyone, and that can also help reason and make sure the quality attributes are satisfied.

Note that the quality attributes requirements usually don't change that frequently, but the decisions in the code do.

**Therefore: Regularly visualize the architecture as the software changes. Compare the architecture as-implemented to your architecture as-intended. If they differ you may want to adjust one or the other. With automated support of Living Diagrams or other Living Documents, this comparison can be done as often as during each build.**

All this assumes you have some vision of what your intended architecture should be. But if you don't have one then you can gradually reverse engineer it from your architecture as-implemented.

There are tools available that can help with architecture visualization and checking, and you can also create your own living diagram generators totally dedicated to your own specific context.


## Decision Log

> Technology is about tradeoffs and choices @simonbrown from Twitter

Why does the project use this particular heavyweight technology? Hopefully it was chosen because of some requirements, following some evaluation. Who remembers that? Now that the works has changed could you switch to something simpler?

What do you talk about during meetings with the stakeholders? From inception meetings to sprint planning meetings and other impromptu meetings, a lot of concepts, thinking and decisions are taken. What happens to all this knowledge?

Sometime it only survives in the mind of the attendees. Sometime it is quickly written as minutes of the meeting and sent by email. Sometime a snapshot of the whiteboard is taken and shared. Some put everything into the tracker tool, or in their wiki.

One common problem in all these cases is that this knowledge lacks structure in the way it is organized

**Therefore: Maintain a Decision Log of the most important architectural decisions. It can be as simple as structured text files in a folder at the root of the code repository. Keep the Decision Log versioned with the code base. For each important decision, record the decision, its rationale (why it was taken), the main alternatives considered, and the main consequences, if any. Never update the entries in the decision log; instead, add a new entry that supersedes the previous one, with a reference to it.**

Michael Nygard calls this decision log an [Architectural Decision Record](http://thinkrelevance.com/blog/2011/11/15/documenting-architecture-decisions), or ADR in short. Nat Pryce created [ADR Tool](https://github.com/npryce/adr-tools) to support them from the command line.

The structuring assumptions that shape the solution are part of the decision log, as part of the rationale for an important decision. For example, if you assume that articles published in the last 24 hours represent over 80% of the visits on your website, then it will show in the rationale for the decision to partition *recent news* vs "archived news" as two distinct sub-systems, each with a different local architecture.

In practice it's not always that easy to record the rationale of major architecture decisions, for example when the decisions are done for the wrong reasons. The managements insisted to include this technology. The developers insisted to try this new library for RÃ©sumÃ©-driven development reasons. It's hard to make that explicit in writing for everyone to see!

![Decision log recording a not so good rationale...](images/why_so_complicated.png)

*You can find good examples of ADR online in the [Arachne-framework
Repository of Architecture Decision Records](https://github.com/arachne-framework/architecture)*

### An example of structured Decision Log

In the example below, the decision log is maintained as a one single Markdown file at the root of the new Claim Management repository, after the vision statement, the description of the business domain and of the main stakeholders.

> Because we want this new micro-service to become the blueprint for many other micro-services to create on top of the existing legacy system, we may end up with other decision logs looking quite similar to each other. When this becomes an issue, we may decide to turn the recurring decisions into a style, document it on one place (e.g. in its own empty repository) and reference it in each service which conforms to this style.


>## The main decisions
>
>To improve the overall User Experience, it has been decided:
>
>- A UX approach, with a focus on beautiful and user-friendly screens, responsive across mobile devices, consistent between them regardless of the actual application behind, and with fast perceived response times. The focus is also on making sure that common tasks can be fulfilled efficiently, with few clicks and few page navigation.
>
>The context of the existing legacy software makes it hard to achieve the vision stated above. This is why a large part of the program is to revamp the legacy, by decommissioning it as much as possible. To mitigate the risks of this decommissioning, the following decisions have been made:
>
>- A Progressive approach, with frequent delivery: no Big Bang. New modules and legacy modules will co-exist, with a progressive migration to new code.
>
>- A Domain-Driven Design approach to help partition the legacy in a way which makes sense at the business domain level, to better understand the domain mechanisms, and to be easier to evolve when the business rules change.
>
>Another challenge is that many business rules are tacit in the mind of senior Adjusters, and need to be formalized. On top of that, with claims taking months to complete, these rules may change during the life of a pending claim. As a consequence, the following decision has been made:
>
>- A Business Process Modeling approach to formalize tacit domain business rules in one place which can be easily audited and changed.
>
>## Consequences
>
>### Risks
>
>One risk is the lack of expertise in the selected approaches. To mitigate this risk, external Experts have been involved:
>
>- UX experts (from the internal UX Center)
>- BPMN expert (Not found yet)
>- DDD expert (from Arolla)
>
>Another risk comes from the legacy context, in particular:
>
>- Cost of testing: the lack of automated tests of all kinds makes each release expensive (manual testing) and/or dangerous (not enough testing)
>- User-Perceived Performance: the legacy is slow, which makes it not suited for the expected response time perceived by end-users.
>
>To reduce the cost of testing, and to not impede the users during all the changes in the legacy, test automation will be key (Unit Tests, Integration Tests, Non Regression Tests) in order to protect the system against regressions or defects
>
>On the issue of user-perceived performance, the design will have to find workarounds to improve the perceived performance even though the legacy code behind may remain slow.
>
>
># Technical Decisions
>
>## new Claim Management as Single Source of Truth until the claim is accepted by the customer
>
>Accepted on 01/12/2015
>
>### Context
>
>We want avoid confusion arising from unclear authority of data, which consumes developer time to fix failing reconciliations. This requires that only source of truth (aka Golden Source) can exist at any point in time for a given piece of domain data.
>
>### Decision
>
>We decide that Claim Management is the only source of truth (aka Golden Source) for Claim on claim inception and until the claim is accepted by the customer, at which time it is **pushed** to the legacy claim mainframe. From the moment it is pushed, the only source of truth is the legacy claim mainframe (LCM).
>
>### Consequences
>
>Given the legacy background, it is unfortunately necessary for some time to have a different Golden Source across the life of a claim. Still, at any point in the life of the claim, the authoritative data are clearly in one single source. This should be re-considered to move to one constant single source whenever possible.
>
>Because of that discrepancy, before the push: commands to create or update a claim are sent to Claim Management, with events sent around and in particular to LCM to sync the LCM data (*Legacy claim mainframe as a Read Model*). After the push: remote calls to LCM are used to update the claim in LCM, with events sent back to Claim Management to sync it (*Claim Management as a Read Model*).
>
>See [CQRS, Read Models and Persistence on InfoQ](https://www.infoq.com/news/2015/10/cqrs-read-models-persistence)
>
>
>## CQRS & Event Sourcing
>
>Accepted on 01/06/2015
>
>### Context
>
>In the claim adjustment domain audit is paramount: we need to be able to tell what happened in an accurate fashion.
>
>We want to exploit the asymmetry between write and read actions to the Claim Management models, in particular to speed up read accesses.
>
>We also want to keep track of the user intents by being more task-oriented.
>
>### Decision
>
>We follow the [CQRS](http://martinfowler.com/bliki/CQRS.html) approach combined with [Event Sourcing](http://martinfowler.com/eaaDev/EventSourcing.html)
>
>### Consequences
>
>We chose [AxonFramework](http://www.axonframework.org) to structure the developments with its ready-made interfaces, annotations and boilerplate code already written.
>
>
>## Value-First
>
>Accepted on 01/06/2015
>
>### Context
>
>We want to avoid bugs that arise from mutability.
>
>We also want reduce the amount of boilerplate code necessary in Java to create value objects.
>
>### Decision
>
>We favor [value objects](http://martinfowler.com/bliki/ValueObject.html) whenever possible. They are immutable, with a valued constructor. They may come with a builder when needed.
>
>### Consequences
>
>We chose [Lombok framework](https://projectlombok.org) to help generate the boilerplate code for value objects and their builders in Java.
>
>

## Journal or Blog as a Brain Dump

An alternative to a formal Decision Log is to dump your brain by telling the full story of what happened, what you learnt and how the team came up with the decisions, tradeoff or a particular implementation detail.

In the book *Software Craftsmanship Apprenticeship Patterns*, Dave Hoover and Adewale Oshineye advocate "Record what you learn" and "Share what you learn". A blog from the team members is a nice complement to any other kind of documentation. Though it is more personal, it tells stories that are more compelling that most documentation. It tells important bits of the adventure, with the feelings of the people that were part of it.

[Dan North](https://twitter.com/tastapod) seems to agree on Twitter, talking to [Liz Kheogh](https://twitter.com/lunivore) and [Jeff Sussna](https://twitter.com/jeffsussna):

> I like having a product and/or team blog. Journalling decisions and conversations as you have them documents history. It also shows how decisions got made, and lets you see changing tastes or learnings over time.


## Fractal Polyglot Architecture

Considering a large system, we should give up on the idea of one single uniform architecture everywhere. A system is made of several sub-systems, and each should have its own architecture, plus the overall architecture of how they're inter-related.

Therefore: **Consider your system as several smaller sub-systems, or "modules". They may be physical units, as components or services, or just logical modules at compile time. Document the architecture independently for each module, and describe the over-arching architecture between the modules as one system-level architecture too.**

Typically you would document the architecture of each module with Internal Documentation, using a combination of package naming conventions, annotations in the source code, and a little plain text. You would document the overall architecture with more Evergreen Documents in plain text, and perhaps some specific DSL if you have one that fits. However the documentation of the overall architecture could also use some generated documents built by consolidation of the knowledge extracted from each module.


## Documentation Landscape

Ready-made architecture document templates may help, if you like them:

- Arc42
- IBM/Rational RUP
- Company-specific set of templates, as a Documentation landscape


Some templates try to plan for every possible architectural documentation need. I totally hate  having to laboriously fill large templates.

Another positive side of templates is as extensive checklists. For example, the ARC 42 "Concepts" section is a nice checklist to find out what you may've forgotten to consider, as shown below (the list is shortened from the [original template](http://www.arc42.org/))

- Ergonomics
- Transaction Processing
- Session Handling
- Security
- Safety
- Communication and Integration
- Plausibility and Validity Checks
- Exception/Error Handling
- System Management and Administration
- Logging, Tracing
- Configurability
- Parallelization and Threading
- Internationalization
- Migration
- Scaling, Clustering
- High Availability
- (...)

How many of these aspects do you neglect in your current project? How many of them do you neglect to document?

Draw inspiration from all these established formalisms to derive your own documentation landscape, on a *module by module* basis. According to Stake-Driven Architecture Documentation, focus each documentation landscape on what matters most for the stakes of this sub-system.

On a module with a rich business domain, you would focus primarily on the domain model and its behaviors as key scenarios. On a module more CRUDdy, there may be very little to say, as everything is probably standard and obvious. On a legacy system, the testability and migration may be the most challenging aspects, which would probably deserve the documentation.

Your documentation landscape can be a plain text file with predefined bullets and tables, but it can take the form of a small annotations library, to directly mark the source code elements with their architectural contribution and rationale. It could be a specific DSL. In practice you would mix all these ideas according to what works best. You may even use a Wiki, or even proprietary tools which would instantly solve all your problems...

A typical documentation landscape for a system would have to at least describe the following points:

1. The overall purpose of the system, its context, users and stakeholders
1. The overall required quality attributes
1. The key business behaviors, and business rules and business vocabulary
1. The overall principles, architecture, technical style and any opinionated decision or parti

This does not mean at all that you need to create documents with all that. Living documentation is all about reducing the need for manually written documents, thanks to alternatives which are cheaper and remain up-to-date.

For example, we could use plain text Evergreen Documents for the first point, system-level acceptance tests for the point 2, a BDD approach with automation for point 3, and a mix of a README, a Codex and custom annotations in the source code for point 4.


## Architecture Diagrams & Notations

Many authors have proposed formalisms to describe software architecture since a long time. A number of standards is available, like IEEE 1471 "Recommended Practice for Architecture Description of Software-Intensive Systems", ISO/IEC/IEEE 42010 "Systems and software engineering â Architecture description", while the Philippe Kruchten's "4+1 model" has gained recognition in the enterprise world. However all these approaches are not precisely *ligthtweigh* and require some learning curve to be understood. The provide a set of "views" to describe different aspects of the software system, with a logical view, a physical view etc. Overall, these approaches are not particularly popular among developers.

Simon Brown acknowledged this need and consequently proposed the [C4 Model](http://www.codingthearchitecture.com/2014/08/24/c4_model_poster.html), a lightweight approach to architecture diagrams which is becoming increasingly popular among developers. This approach draws in particular from the work of Eoin Woods and Nick Rozanski in their book [Software Systems Architecture](http://www.viewpoints-and-perspectives.info), and has the benefit of being usable without prior training. It suggests 4 simple types of diagrams to describe a software architecture:

- **System Context Diagram**: A starting point for diagramming and documenting a software system, allowing you to step back and look at the big picture
- **Container Diagram**: To illustrate the high-level technology choices, showing web application, desktop application, mobile app, database, file system
- **Components Diagram**: A way to zoom into a container, by decomposing in a way that makes sense to you: services, subsystems, layers, workflows etc.
- **Classes Diagrams**: (Optional) To illustrate any specific implementation detail with one or more UML class diagram(s).

My favorite is the Context Diagram, both simple, obvious but so often neglected.

## Architecture Codex

When describing a solution to people, probably the most critical part is to share the thinking and reasoning which led to the solution.

Rebecca Wirfs-Brock was at the ITAKE un-conference in Bucharest in 2012, and during her talk and the later conversations we had about it, she gave the example of EcmaScript, where the thinking process is clearly documented:

Here are from my notes on the topic some of the rationale for decisions in EcmaScript:

- "Invoke similarities with other existing folklore"
- "Usually we want to learn and understand as little as possible to do the job."
- "Recipe for making change: figure out how similar change has been done before."

Later I have been doing department-wide architecture in a bank, and I introduced this idea of a Codex of principles guiding all the architecture-sensitive decisions. The Codex was built from the accumulation of concrete cases of decision-making, by trying to elucidate formally the reasoning behind the decision. Often, the principle was already in the head of other senior architects, but it was tacit and nobody else knew about it.

![The all-mighty Codex](images/codex.png)

Some of these principles were like the following:

- "Know your golden source" (aka Single Source of Truth)
- "Don't feed the monster": improving the legacy only helps last it longer
- Increase the Straight-Through Processing Automation Ratio
- Customer convenience first
- API-First!
- "Manual process is just a special case of an electronic process"


This codex proved useful for everybody involved in architecture. The goal was to publish it for everyone, even if it was incomplete and not always easy to understand. At least it was useful to provoke questions and reactions. It was never formally published as far as I know, however its content leaked on many occasions and has been used several times for more consistent decision-making.

One recent consulting gigs I found it helpful again to express the value referential of the team as a list of preferences, like:

- "Code over XML"
- "Templating engine is ok but keep the logic out"

Of course it is a good idea to adopt standard principles already documented in the literature too, as a kind of READY MADE DOCUMENTATION. For example:

- "Keep your middleware dumb, and keep the smarts in the endpoints." by Sam Newman

It is very important to keep this codex as a working document, never finished. Whenever we hit a contraction in its principles, then it's time to fix it or evolve it. This did happen, and this should not be seen as a failure, but as an opportunity for collective decision-making to be even more relevant. After all, architecture is a kind of a consensus thing, isn't it?

An architecture codex can be just a text file in the source control, a set of slides, and it can even be expressed in code. The following is an example of using a simple enum to materialize the principles of the codex:

~~~~~~~~
/**
 * The list of all principles the team agrees on.
 */
public enum Codex {

	/** We have no clue to explain this decision */
	NO_CLUE("Nobody"),

	/** There must be only one authoritative place for each piece of data. */
	SINGLE_GOLDEN_SOURCE("Team"),

	/** Keep your middleware dumb, and keep the smarts in the endpoints. */
	DUMP_MIDDLEWARE("Sam Newman");

	private final String author;

	private Codex(String author) {
		this.author = author;
	}
}
~~~~~~~~

Sam Newman in his book "Building Microservices" mentions his colleague Evan Bottcher created a big poster on the wall displaying the key principles visibly on the wall, organized in three columns from left to right:

> ## Principles on a poster on the wall
>
> - Strategic Goals, like "Enable Scalable Business", "Support Entry into new Markets"
> - Architectural Principles, like "Consistent Interfaces and Data Flow", "No Silver Bullet".
> - Design & Delivery Practices, like "Standard REST/http", "Encapsulate Legacy", or "Minimal Customization of COTS/SAAS".

That's a nice way to sum up the system vision, principles and practices in one place!

## Transparent Architecture

When architecture documentation becomes embedded within the software artifacts themselves in each source code repository, with Living Diagrams and Living Documents generated out of them automatically, everyone gets access to all the architecture knowledge by themselves. Contrast that with companies where the architecture knowledge remains in tools and slide-decks only known by the official architects, and not up-to-date.

One consequence is that this enables decentralizing the architecture and the decision making dependent on architecture knowledge. I call that "transparent architecture": if everyone can see the quality of the architecture by themselves, then they can take decisions accordingly, by themselves, without necessarily asking the people in an architect role.

![With access to the whole picture, each team can directly take decisions consistent with respect to the whole system](images/transparent_architecture.png)

For example, in a microservices architecture, a transparent architecture will make use of Living System Diagrams generated out of the working system at runtime. This knowledge is already there in the distributed tracing infrastructure (e.g. Zipkin). You may have to augment it a bit with custom annotations and binary annotations added in your instrumentation.

You may as well rely on your Service Registry (e.g. Consul, Eureka...) and its tags to produce Living Documents. Dependencies between services can also be derived from the Consumer-Driven Contracts, if you apply this practice. And if you care about the physical infrastructure, it can be made visible through custom Living Diagrams generated with Graphviz from data you get from your Cloud through its programmatic API. Note that more "virtuous" practices also makes living documentation easier!

![Living Diagram of a Cloud infrastructure generated from cron, python, boto, pydot, graphviz - from James Lewis slides ](images/james_lewis_cloud_diagram.png)


*All this is fine, but we can go even further with Test-Driven Architecture.*
